{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1,80,82,103,104,105,106,107,108,111,112,113,114,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "df = pd.read_csv('df5.tsv', sep=\"\\t\")\n",
    "df.replace('.', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1008 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df=df, figsize=(20,14), color=(0.5,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics=['#chr','pos','ref','alt','gene','value','confidence', 'WhatSet']\n",
    "caddn=[ 'ConsScore',  'GC', 'CpG', 'mapAbility20bp', 'mapAbility35bp',  'priPhCons', 'mamPhCons', 'verPhCons', 'priPhyloP', 'mamPhyloP', 'verPhyloP', 'GerpN', 'GerpS', 'GerpRS', 'GerpRSpval', 'bStatistic', 'mutIndex', 'dnaHelT', 'dnaMGW', 'dnaProT', 'dnaRoll','fitCons', 'cHmmTssA', 'cHmmTssAFlnk', 'cHmmTxFlnk', 'cHmmTx', 'cHmmTxWk', 'cHmmEnhG', 'cHmmEnh',  'cHmmHet', 'cHmmTssBiv', 'cHmmBivFlnk', 'cHmmEnhBiv', 'cHmmReprPC', 'cHmmReprPCWk', 'cHmmQuies', 'EncExp', 'EncH3K27Ac', 'EncH3K4Me1', 'EncH3K4Me3', 'EncNucleo', 'EncOCC', 'EncOCCombPVal', 'EncOCDNasePVal', 'EncOCFairePVal', 'EncOCpolIIPVal', 'EncOCctcfPVal', 'EncOCmycPVal', 'EncOCDNaseSig', 'EncOCFaireSig', 'EncOCpolIISig', 'EncOCctcfSig', 'EncOCmycSig',  'motifEScoreChng', 'minDistTSS', 'minDistTSE','relcDNApos', 'CDSpos', 'relCDSpos', 'PHRED']\n",
    "caddc=['AnnoType','Consequence','ConsDetail',  'Segway', 'tOverlapMotifs',  'motifEName','isKnownVariant', 'Dst2SplType']\n",
    "caddn0=['motifECount','TFBS',  'TFBSPeaks',  'TFBSPeaksMax', 'TG_AF']\n",
    "caddabs=[ 'motifDist','Dst2Splice']\n",
    "notsure=['mirSVR-Score', 'mirSVR-E', 'mirSVR-Aln', 'targetScan' ]\n",
    "\n",
    "defc=['RegulomeDB_score','network_hub','sensitive','target_gene','fathmm-MKL_non-coding_pred','fathmm-MKL_coding_group','hESC_Topological_Domain','IMR90_Topological_Domain','ENCODE_TFBS','ENCODE_Dnase_score','Ensembl_Regulatory_Build_feature_type','Ensembl_Regulatory_Build_TFBS']\n",
    "cellt=['Ensembl_HeLa_S3_activity','Ensembl_HELAS3_segmentation','ENCODE_Helas3_segmentation','Ensembl_K562_activity','Ensembl_K562_segmentation','ENCODE_K562_segmentation','Ensembl_HepG2_activity','Ensembl_HEPG2_segmentation','ENCODE_Hepg2_segmentation']\n",
    "defn=['MAP20','MAP35','MAP20(+-149bp)','MAP35(+-149bp)','GMS_single-end','GMS_paired-end','phastCons100way_vertebrate_rankscore','GERP_RS_rankscore','integrated_fitCons_rankscore','GM12878_fitCons_rankscore','H1-hESC_fitCons_rankscore','HUVEC_fitCons_rankscore','GenoCanyon_rankscore','funseq_noncoding_score','funseq2_noncoding_rankscore','CADD_phred','DANN_rank_score','fathmm-MKL_non-coding_rankscore','Eigen-PC-phred']\n",
    "defn0=['splicing_consensus_ada_score','splicing_consensus_rf_score','1000Gp3_AC','UK10K_AC','TWINSUK_AC','gnomAD_genomes_AC']\n",
    "maybec=['ANNOVAR_ensembl_Effect','SnpEff_ensembl_Effect','SnpEff_ensembl_Effect_impact','SnpEff_ensembl_Distance_to_feature','SnpEff_ensembl_TF_binding_effect','SnpEff_ensembl_TF_name','SnpEff_ensembl_summary','RegulomeDB_motif','Motif_breaking','ENCODE_annotated','FANTOM5_enhancer_differentially_expressed_tissue_cell']\n",
    "\n",
    "o1=['ENCODE_TFBS_score']\n",
    "possc=['ORegAnno_type', 'FANTOM5_CAGE_peak_permissive']\n",
    "\n",
    "mc=['meanDNase.macs2', 'meanH2A.Z', 'meanH2AK5ac', 'meanH2AK9ac', 'meanH2BK120ac', 'meanH2BK12ac', 'meanH2BK15ac', 'meanH2BK20ac', 'meanH2BK5ac', 'meanH3K14ac', 'meanH3K18ac', 'meanH3K23ac', 'meanH3K23me2', 'meanH3K27ac', 'meanH3K27me3', 'meanH3K36me3', 'meanH3K4ac', 'meanH3K4me1', 'meanH3K4me2', 'meanH3K4me3', 'meanH3K56ac', 'meanH3K79me1', 'meanH3K79me2', 'meanH3K9ac', 'meanH3K9me1', 'meanH3K9me3', 'meanH3T11ph', 'meanH4K12ac', 'meanH4K20me1', 'meanH4K5ac', 'meanH4K8ac', 'meanH4K91ac', 'meanDNase.hotspot.all', 'meanDNase.hotspot.fdr0.01', 'meanRoadmap']\n",
    "\n",
    "aacols=['valuec', 'Trimer', 'TrimerAvg', 'TrimerMut','Tetra']\n",
    "##df['scoreSegDup'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in caddn0:\n",
    "    df[i]=df[i].fillna(0)\n",
    "for j in defn0:\n",
    "    df[j]=df[j].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['multic']=df.apply(lambda x: -1.0 if (x['value'] < -0.08) else 0 if (x['value'] >= -0.08 and x['value'] < 0.08) else 1.0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feats=caddn+caddn0+caddabs+defn+defn0+['TrimerAvg']\n",
    "cat_feats=caddc+defc+['Trimer','TrimerMut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: convert_objects is deprecated.  Use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df[numeric_feats]=df[numeric_feats].convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing gene  SORT1\n",
      "Imputing row 1/1790 with 8 missing, elapsed time: 2.300\n",
      "Imputing row 101/1790 with 6 missing, elapsed time: 2.318\n",
      "Imputing row 201/1790 with 6 missing, elapsed time: 2.337\n",
      "Imputing row 301/1790 with 6 missing, elapsed time: 2.355\n",
      "Imputing row 401/1790 with 7 missing, elapsed time: 2.373\n",
      "Imputing row 501/1790 with 7 missing, elapsed time: 2.393\n",
      "Imputing row 601/1790 with 7 missing, elapsed time: 2.412\n",
      "Imputing row 701/1790 with 6 missing, elapsed time: 2.429\n",
      "Imputing row 801/1790 with 6 missing, elapsed time: 2.448\n",
      "Imputing row 901/1790 with 6 missing, elapsed time: 2.466\n",
      "Imputing row 1001/1790 with 6 missing, elapsed time: 2.484\n",
      "Imputing row 1101/1790 with 7 missing, elapsed time: 2.508\n",
      "Imputing row 1201/1790 with 6 missing, elapsed time: 2.527\n",
      "Imputing row 1301/1790 with 7 missing, elapsed time: 2.546\n",
      "Imputing row 1401/1790 with 7 missing, elapsed time: 2.565\n",
      "Imputing row 1501/1790 with 7 missing, elapsed time: 2.585\n",
      "Imputing row 1601/1790 with 7 missing, elapsed time: 2.604\n",
      "Imputing row 1701/1790 with 7 missing, elapsed time: 2.623\n",
      "[KNN] Warning: 8950/166470 still missing after imputation, replacing with 0\n",
      "Doing gene  PKLR\n",
      "Imputing row 1/1409 with 8 missing, elapsed time: 2.634\n",
      "Imputing row 101/1409 with 9 missing, elapsed time: 2.689\n",
      "Imputing row 201/1409 with 9 missing, elapsed time: 2.742\n",
      "Imputing row 301/1409 with 10 missing, elapsed time: 2.809\n",
      "Imputing row 401/1409 with 9 missing, elapsed time: 2.869\n",
      "Imputing row 501/1409 with 8 missing, elapsed time: 2.917\n",
      "Imputing row 601/1409 with 7 missing, elapsed time: 2.967\n",
      "Imputing row 701/1409 with 9 missing, elapsed time: 3.019\n",
      "Imputing row 801/1409 with 10 missing, elapsed time: 3.078\n",
      "Imputing row 901/1409 with 9 missing, elapsed time: 3.143\n",
      "Imputing row 1001/1409 with 9 missing, elapsed time: 3.183\n",
      "Imputing row 1101/1409 with 10 missing, elapsed time: 3.213\n",
      "Imputing row 1201/1409 with 9 missing, elapsed time: 3.244\n",
      "Imputing row 1301/1409 with 9 missing, elapsed time: 3.274\n",
      "Imputing row 1401/1409 with 8 missing, elapsed time: 3.305\n",
      "[KNN] Warning: 2818/131037 still missing after imputation, replacing with 0\n",
      "Doing gene  IRF6\n",
      "Imputing row 1/1786 with 10 missing, elapsed time: 3.228\n",
      "Imputing row 101/1786 with 7 missing, elapsed time: 3.254\n",
      "Imputing row 201/1786 with 6 missing, elapsed time: 3.273\n",
      "Imputing row 301/1786 with 7 missing, elapsed time: 3.293\n",
      "Imputing row 401/1786 with 10 missing, elapsed time: 3.315\n",
      "Imputing row 501/1786 with 10 missing, elapsed time: 3.344\n",
      "Imputing row 601/1786 with 10 missing, elapsed time: 3.373\n",
      "Imputing row 701/1786 with 8 missing, elapsed time: 3.395\n",
      "Imputing row 801/1786 with 7 missing, elapsed time: 3.438\n",
      "Imputing row 901/1786 with 8 missing, elapsed time: 3.469\n",
      "Imputing row 1001/1786 with 8 missing, elapsed time: 3.511\n",
      "Imputing row 1101/1786 with 7 missing, elapsed time: 3.551\n",
      "Imputing row 1201/1786 with 6 missing, elapsed time: 3.580\n",
      "Imputing row 1301/1786 with 7 missing, elapsed time: 3.601\n",
      "Imputing row 1401/1786 with 8 missing, elapsed time: 3.621\n",
      "Imputing row 1501/1786 with 7 missing, elapsed time: 3.641\n",
      "Imputing row 1601/1786 with 10 missing, elapsed time: 3.669\n",
      "Imputing row 1701/1786 with 10 missing, elapsed time: 3.697\n",
      "[KNN] Warning: 10716/166098 still missing after imputation, replacing with 0\n",
      "Doing gene  MSMB\n",
      "Imputing row 1/1149 with 22 missing, elapsed time: 1.262\n",
      "Imputing row 101/1149 with 22 missing, elapsed time: 1.348\n",
      "Imputing row 201/1149 with 21 missing, elapsed time: 1.440\n",
      "Imputing row 301/1149 with 21 missing, elapsed time: 1.536\n",
      "Imputing row 401/1149 with 20 missing, elapsed time: 1.622\n",
      "Imputing row 501/1149 with 21 missing, elapsed time: 1.709\n",
      "Imputing row 601/1149 with 22 missing, elapsed time: 1.763\n",
      "Imputing row 701/1149 with 21 missing, elapsed time: 1.812\n",
      "Imputing row 801/1149 with 20 missing, elapsed time: 1.861\n",
      "Imputing row 901/1149 with 22 missing, elapsed time: 1.910\n",
      "Imputing row 1001/1149 with 22 missing, elapsed time: 1.960\n",
      "Imputing row 1101/1149 with 21 missing, elapsed time: 2.041\n",
      "[KNN] Warning: 20682/106857 still missing after imputation, replacing with 0\n",
      "Doing gene  HBB\n",
      "Imputing row 1/564 with 20 missing, elapsed time: 0.311\n",
      "Imputing row 101/564 with 22 missing, elapsed time: 0.386\n",
      "Imputing row 201/564 with 19 missing, elapsed time: 0.475\n",
      "Imputing row 301/564 with 20 missing, elapsed time: 0.554\n",
      "Imputing row 401/564 with 20 missing, elapsed time: 0.631\n",
      "Imputing row 501/564 with 22 missing, elapsed time: 0.723\n",
      "[KNN] Warning: 9588/52452 still missing after imputation, replacing with 0\n",
      "Doing gene  HBG1\n",
      "Imputing row 1/825 with 10 missing, elapsed time: 0.813\n",
      "Imputing row 101/825 with 10 missing, elapsed time: 0.859\n",
      "Imputing row 201/825 with 10 missing, elapsed time: 0.890\n",
      "Imputing row 301/825 with 10 missing, elapsed time: 0.940\n",
      "Imputing row 401/825 with 9 missing, elapsed time: 0.964\n",
      "Imputing row 501/825 with 9 missing, elapsed time: 0.986\n",
      "Imputing row 601/825 with 10 missing, elapsed time: 1.009\n",
      "Imputing row 701/825 with 9 missing, elapsed time: 1.035\n",
      "Imputing row 801/825 with 8 missing, elapsed time: 1.055\n",
      "[KNN] Warning: 5775/76725 still missing after imputation, replacing with 0\n",
      "Doing gene  LDLR\n",
      "Imputing row 1/955 with 8 missing, elapsed time: 0.921\n",
      "Imputing row 101/955 with 7 missing, elapsed time: 0.971\n",
      "Imputing row 201/955 with 9 missing, elapsed time: 1.002\n",
      "Imputing row 301/955 with 8 missing, elapsed time: 1.055\n",
      "Imputing row 401/955 with 9 missing, elapsed time: 1.103\n",
      "Imputing row 501/955 with 7 missing, elapsed time: 1.140\n",
      "Imputing row 601/955 with 4 missing, elapsed time: 1.171\n",
      "Imputing row 701/955 with 7 missing, elapsed time: 1.223\n",
      "Imputing row 801/955 with 9 missing, elapsed time: 1.266\n",
      "Imputing row 901/955 with 7 missing, elapsed time: 1.311\n",
      "[KNN] Warning: 3820/88815 still missing after imputation, replacing with 0\n",
      "Doing gene  HNF4A\n",
      "Imputing row 1/858 with 20 missing, elapsed time: 1.046\n",
      "Imputing row 101/858 with 19 missing, elapsed time: 1.084\n",
      "Imputing row 201/858 with 21 missing, elapsed time: 1.124\n",
      "Imputing row 301/858 with 20 missing, elapsed time: 1.165\n",
      "Imputing row 401/858 with 20 missing, elapsed time: 1.204\n",
      "Imputing row 501/858 with 19 missing, elapsed time: 1.259\n",
      "Imputing row 601/858 with 20 missing, elapsed time: 1.335\n",
      "Imputing row 701/858 with 19 missing, elapsed time: 1.380\n",
      "Imputing row 801/858 with 19 missing, elapsed time: 1.418\n",
      "[KNN] Warning: 15444/79794 still missing after imputation, replacing with 0\n",
      "Doing gene  GP1BB\n",
      "Imputing row 1/1157 with 7 missing, elapsed time: 1.502\n",
      "Imputing row 101/1157 with 9 missing, elapsed time: 1.547\n",
      "Imputing row 201/1157 with 8 missing, elapsed time: 1.599\n",
      "Imputing row 301/1157 with 7 missing, elapsed time: 1.661\n",
      "Imputing row 401/1157 with 7 missing, elapsed time: 1.710\n",
      "Imputing row 501/1157 with 6 missing, elapsed time: 1.751\n",
      "Imputing row 601/1157 with 9 missing, elapsed time: 1.804\n",
      "Imputing row 701/1157 with 7 missing, elapsed time: 1.860\n",
      "Imputing row 801/1157 with 9 missing, elapsed time: 1.923\n",
      "Imputing row 901/1157 with 9 missing, elapsed time: 1.987\n",
      "Imputing row 1001/1157 with 6 missing, elapsed time: 2.030\n",
      "Imputing row 1101/1157 with 9 missing, elapsed time: 2.079\n",
      "Doing gene  TERT-GBM\n",
      "Imputing row 1/775 with 5 missing, elapsed time: 0.760\n",
      "Imputing row 101/775 with 9 missing, elapsed time: 0.804\n",
      "Imputing row 201/775 with 8 missing, elapsed time: 0.852\n",
      "Imputing row 301/775 with 9 missing, elapsed time: 0.899\n",
      "Imputing row 401/775 with 9 missing, elapsed time: 0.945\n",
      "Imputing row 501/775 with 10 missing, elapsed time: 0.983\n",
      "Imputing row 601/775 with 10 missing, elapsed time: 1.012\n",
      "Imputing row 701/775 with 9 missing, elapsed time: 1.041\n",
      "[KNN] Warning: 775/72075 still missing after imputation, replacing with 0\n",
      "Doing gene  IRF4\n",
      "Imputing row 1/1356 with 9 missing, elapsed time: 2.474\n",
      "Imputing row 101/1356 with 7 missing, elapsed time: 2.513\n",
      "Imputing row 201/1356 with 18 missing, elapsed time: 2.587\n",
      "Imputing row 301/1356 with 21 missing, elapsed time: 2.673\n",
      "Imputing row 401/1356 with 9 missing, elapsed time: 2.712\n",
      "Imputing row 501/1356 with 6 missing, elapsed time: 2.723\n",
      "Imputing row 601/1356 with 7 missing, elapsed time: 2.734\n",
      "Imputing row 701/1356 with 19 missing, elapsed time: 2.762\n",
      "Imputing row 801/1356 with 18 missing, elapsed time: 2.840\n",
      "Imputing row 901/1356 with 19 missing, elapsed time: 2.943\n",
      "Imputing row 1001/1356 with 21 missing, elapsed time: 3.068\n",
      "Imputing row 1101/1356 with 20 missing, elapsed time: 3.174\n",
      "Imputing row 1201/1356 with 21 missing, elapsed time: 3.289\n",
      "Imputing row 1301/1356 with 21 missing, elapsed time: 3.392\n",
      "[KNN] Warning: 6780/126108 still missing after imputation, replacing with 0\n",
      "Doing gene  ZFAND3\n",
      "Imputing row 1/1738 with 22 missing, elapsed time: 2.269\n",
      "Imputing row 101/1738 with 22 missing, elapsed time: 2.334\n",
      "Imputing row 201/1738 with 19 missing, elapsed time: 2.394\n",
      "Imputing row 301/1738 with 8 missing, elapsed time: 2.431\n",
      "Imputing row 401/1738 with 10 missing, elapsed time: 2.454\n",
      "Imputing row 501/1738 with 22 missing, elapsed time: 2.491\n",
      "Imputing row 601/1738 with 22 missing, elapsed time: 2.553\n",
      "Imputing row 701/1738 with 21 missing, elapsed time: 2.614\n",
      "Imputing row 801/1738 with 22 missing, elapsed time: 2.677\n",
      "Imputing row 901/1738 with 20 missing, elapsed time: 2.742\n",
      "Imputing row 1001/1738 with 19 missing, elapsed time: 2.803\n",
      "Imputing row 1101/1738 with 7 missing, elapsed time: 2.851\n",
      "Imputing row 1201/1738 with 8 missing, elapsed time: 2.871\n",
      "Imputing row 1301/1738 with 7 missing, elapsed time: 2.888\n",
      "Imputing row 1401/1738 with 10 missing, elapsed time: 2.909\n",
      "Imputing row 1501/1738 with 8 missing, elapsed time: 2.936\n",
      "Imputing row 1601/1738 with 10 missing, elapsed time: 2.966\n",
      "Imputing row 1701/1738 with 10 missing, elapsed time: 2.992\n",
      "[KNN] Warning: 10428/161634 still missing after imputation, replacing with 0\n",
      "Doing gene  MYCrs6983267\n",
      "Imputing row 1/428 with 10 missing, elapsed time: 0.143\n",
      "Imputing row 101/428 with 8 missing, elapsed time: 0.164\n",
      "Imputing row 201/428 with 8 missing, elapsed time: 0.179\n",
      "Imputing row 301/428 with 63 missing, elapsed time: 0.200\n",
      "Imputing row 401/428 with 8 missing, elapsed time: 0.230\n",
      "[KNN] Warning: 2140/39804 still missing after imputation, replacing with 0\n",
      "Doing gene  F9\n",
      "Imputing row 1/907 with 29 missing, elapsed time: 0.905\n",
      "Imputing row 101/907 with 27 missing, elapsed time: 1.016\n",
      "Imputing row 201/907 with 26 missing, elapsed time: 1.131\n",
      "Imputing row 301/907 with 29 missing, elapsed time: 1.241\n",
      "Imputing row 401/907 with 27 missing, elapsed time: 1.330\n",
      "Imputing row 501/907 with 29 missing, elapsed time: 1.399\n",
      "Imputing row 601/907 with 27 missing, elapsed time: 1.458\n",
      "Imputing row 701/907 with 26 missing, elapsed time: 1.515\n",
      "Imputing row 801/907 with 27 missing, elapsed time: 1.629\n",
      "Imputing row 901/907 with 25 missing, elapsed time: 1.707\n",
      "[KNN] Warning: 19047/84351 still missing after imputation, replacing with 0\n",
      "Doing gene  MYC\n",
      "Imputing row 1/1364 with 8 missing, elapsed time: 2.755\n",
      "Imputing row 101/1364 with 7 missing, elapsed time: 2.788\n",
      "Imputing row 201/1364 with 7 missing, elapsed time: 2.822\n",
      "Imputing row 301/1364 with 8 missing, elapsed time: 2.875\n",
      "Imputing row 401/1364 with 8 missing, elapsed time: 2.920\n",
      "Imputing row 501/1364 with 7 missing, elapsed time: 2.968\n",
      "Imputing row 601/1364 with 8 missing, elapsed time: 3.012\n",
      "Imputing row 701/1364 with 7 missing, elapsed time: 3.065\n",
      "Imputing row 801/1364 with 63 missing, elapsed time: 3.261\n",
      "Imputing row 901/1364 with 64 missing, elapsed time: 3.654\n",
      "Imputing row 1001/1364 with 62 missing, elapsed time: 4.058\n",
      "Imputing row 1101/1364 with 63 missing, elapsed time: 4.265\n",
      "Imputing row 1201/1364 with 7 missing, elapsed time: 4.648\n",
      "Imputing row 1301/1364 with 8 missing, elapsed time: 4.690\n",
      "[KNN] Warning: 5456/126852 still missing after imputation, replacing with 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ConsScore</th>\n",
       "      <th>GC</th>\n",
       "      <th>CpG</th>\n",
       "      <th>mapAbility20bp</th>\n",
       "      <th>mapAbility35bp</th>\n",
       "      <th>priPhCons</th>\n",
       "      <th>mamPhCons</th>\n",
       "      <th>verPhCons</th>\n",
       "      <th>priPhyloP</th>\n",
       "      <th>mamPhyloP</th>\n",
       "      <th>...</th>\n",
       "      <th>DANN_rank_score</th>\n",
       "      <th>fathmm-MKL_non-coding_rankscore</th>\n",
       "      <th>Eigen-PC-phred</th>\n",
       "      <th>splicing_consensus_ada_score</th>\n",
       "      <th>splicing_consensus_rf_score</th>\n",
       "      <th>1000Gp3_AC</th>\n",
       "      <th>UK10K_AC</th>\n",
       "      <th>TWINSUK_AC</th>\n",
       "      <th>gnomAD_genomes_AC</th>\n",
       "      <th>TrimerAvg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97528</td>\n",
       "      <td>0.98089</td>\n",
       "      <td>22.5234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.211141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96103</td>\n",
       "      <td>0.98105</td>\n",
       "      <td>22.5234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97675</td>\n",
       "      <td>0.98032</td>\n",
       "      <td>22.5234</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97063</td>\n",
       "      <td>0.97882</td>\n",
       "      <td>22.5344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.181379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93453</td>\n",
       "      <td>0.97854</td>\n",
       "      <td>22.5344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93344</td>\n",
       "      <td>0.97900</td>\n",
       "      <td>22.5344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97517</td>\n",
       "      <td>0.98065</td>\n",
       "      <td>22.5658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95522</td>\n",
       "      <td>0.98124</td>\n",
       "      <td>22.5658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.458889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97399</td>\n",
       "      <td>0.98098</td>\n",
       "      <td>22.5658</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97509</td>\n",
       "      <td>0.98089</td>\n",
       "      <td>22.5881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96087</td>\n",
       "      <td>0.98105</td>\n",
       "      <td>22.5881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97652</td>\n",
       "      <td>0.98032</td>\n",
       "      <td>22.5881</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93172</td>\n",
       "      <td>0.97912</td>\n",
       "      <td>22.5917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93210</td>\n",
       "      <td>0.97887</td>\n",
       "      <td>22.5917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96952</td>\n",
       "      <td>0.97888</td>\n",
       "      <td>22.5917</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.065882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97022</td>\n",
       "      <td>0.97882</td>\n",
       "      <td>22.6590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.277857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93234</td>\n",
       "      <td>0.97854</td>\n",
       "      <td>22.6590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93232</td>\n",
       "      <td>0.97900</td>\n",
       "      <td>22.6590</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.304091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97482</td>\n",
       "      <td>0.98065</td>\n",
       "      <td>22.6896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.194868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.95410</td>\n",
       "      <td>0.98124</td>\n",
       "      <td>22.6896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.458889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97354</td>\n",
       "      <td>0.98098</td>\n",
       "      <td>22.6896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93050</td>\n",
       "      <td>0.97912</td>\n",
       "      <td>22.6431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.170652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93252</td>\n",
       "      <td>0.97887</td>\n",
       "      <td>22.6431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96870</td>\n",
       "      <td>0.97888</td>\n",
       "      <td>22.6431</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93050</td>\n",
       "      <td>0.97912</td>\n",
       "      <td>22.6369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.93252</td>\n",
       "      <td>0.97887</td>\n",
       "      <td>22.6369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.455</td>\n",
       "      <td>2.032</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96870</td>\n",
       "      <td>0.97888</td>\n",
       "      <td>22.6369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.167308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97476</td>\n",
       "      <td>0.98089</td>\n",
       "      <td>22.6738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.201250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.96049</td>\n",
       "      <td>0.98105</td>\n",
       "      <td>22.6738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.512</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97612</td>\n",
       "      <td>0.98032</td>\n",
       "      <td>22.6738</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16360</th>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94316</td>\n",
       "      <td>0.99187</td>\n",
       "      <td>18.0687</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16361</th>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94762</td>\n",
       "      <td>0.99177</td>\n",
       "      <td>18.0736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16362</th>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.87343</td>\n",
       "      <td>0.99187</td>\n",
       "      <td>18.0736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16363</th>\n",
       "      <td>4</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94433</td>\n",
       "      <td>0.99138</td>\n",
       "      <td>18.0736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16364</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76653</td>\n",
       "      <td>0.97673</td>\n",
       "      <td>17.6863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16365</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.66923</td>\n",
       "      <td>0.97673</td>\n",
       "      <td>17.6863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16366</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70343</td>\n",
       "      <td>0.97581</td>\n",
       "      <td>17.6863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.141604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16367</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.91490</td>\n",
       "      <td>0.98163</td>\n",
       "      <td>17.7454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.181379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16368</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85877</td>\n",
       "      <td>0.98114</td>\n",
       "      <td>17.7454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.107647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16369</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84657</td>\n",
       "      <td>0.98180</td>\n",
       "      <td>17.7454</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.143000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16370</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40986</td>\n",
       "      <td>0.97180</td>\n",
       "      <td>17.5270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.105769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16371</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.49639</td>\n",
       "      <td>0.97085</td>\n",
       "      <td>17.5270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.167308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16372</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76591</td>\n",
       "      <td>0.97670</td>\n",
       "      <td>17.7196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.201250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16373</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.77179</td>\n",
       "      <td>0.97669</td>\n",
       "      <td>17.7196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16374</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.180</td>\n",
       "      <td>0.241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63616</td>\n",
       "      <td>0.97596</td>\n",
       "      <td>17.7196</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16375</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.968</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70816</td>\n",
       "      <td>0.97439</td>\n",
       "      <td>17.7793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16376</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.968</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67881</td>\n",
       "      <td>0.97485</td>\n",
       "      <td>17.7793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16377</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.968</td>\n",
       "      <td>-0.144</td>\n",
       "      <td>0.696</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61037</td>\n",
       "      <td>0.97470</td>\n",
       "      <td>17.7793</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16378</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.68636</td>\n",
       "      <td>0.97657</td>\n",
       "      <td>17.8690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16379</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.70324</td>\n",
       "      <td>0.97583</td>\n",
       "      <td>17.8690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16380</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.81402</td>\n",
       "      <td>0.97629</td>\n",
       "      <td>17.8690</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.120962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16381</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.72138</td>\n",
       "      <td>0.98021</td>\n",
       "      <td>17.9016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.322500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16382</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.67765</td>\n",
       "      <td>0.98050</td>\n",
       "      <td>17.9016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.458889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16383</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.651</td>\n",
       "      <td>1.122</td>\n",
       "      <td>...</td>\n",
       "      <td>0.76342</td>\n",
       "      <td>0.97899</td>\n",
       "      <td>17.9016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.123000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16384</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90485</td>\n",
       "      <td>0.99098</td>\n",
       "      <td>18.0379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16385</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.85433</td>\n",
       "      <td>0.99109</td>\n",
       "      <td>18.0379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.377813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16386</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.651</td>\n",
       "      <td>2.572</td>\n",
       "      <td>...</td>\n",
       "      <td>0.86108</td>\n",
       "      <td>0.99056</td>\n",
       "      <td>18.0379</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.283621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16387</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.89756</td>\n",
       "      <td>0.98916</td>\n",
       "      <td>18.0369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.249500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16388</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92571</td>\n",
       "      <td>0.98895</td>\n",
       "      <td>18.0369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16389</th>\n",
       "      <td>4</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.904</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.530</td>\n",
       "      <td>2.079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.94816</td>\n",
       "      <td>0.98896</td>\n",
       "      <td>18.0369</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.120962</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17061 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ConsScore    GC   CpG  mapAbility20bp  mapAbility35bp  priPhCons  \\\n",
       "0              4  0.65  0.05               1               1      0.997   \n",
       "1              4  0.65  0.05               1               1      0.997   \n",
       "2              4  0.65  0.05               1               1      0.997   \n",
       "3              4  0.66  0.05               1               1      0.997   \n",
       "4              4  0.66  0.05               1               1      0.997   \n",
       "5              4  0.66  0.05               1               1      0.997   \n",
       "6              4  0.65  0.05               1               1      0.998   \n",
       "7              4  0.65  0.05               1               1      0.998   \n",
       "8              4  0.65  0.05               1               1      0.998   \n",
       "9              4  0.65  0.05               1               1      0.998   \n",
       "10             4  0.65  0.05               1               1      0.998   \n",
       "11             4  0.65  0.05               1               1      0.998   \n",
       "12             4  0.64  0.05               1               1      0.997   \n",
       "13             4  0.64  0.05               1               1      0.997   \n",
       "14             4  0.64  0.05               1               1      0.997   \n",
       "15             4  0.65  0.05               1               1      0.997   \n",
       "16             4  0.65  0.05               1               1      0.997   \n",
       "17             4  0.65  0.05               1               1      0.997   \n",
       "18             4  0.64  0.05               1               1      0.997   \n",
       "19             4  0.64  0.05               1               1      0.997   \n",
       "20             4  0.64  0.05               1               1      0.997   \n",
       "21             4  0.65  0.05               1               1      0.996   \n",
       "22             4  0.65  0.05               1               1      0.996   \n",
       "23             4  0.65  0.05               1               1      0.996   \n",
       "24             4  0.65  0.05               1               1      0.996   \n",
       "25             4  0.65  0.05               1               1      0.996   \n",
       "26             4  0.65  0.05               1               1      0.996   \n",
       "27             4  0.65  0.05               1               1      0.995   \n",
       "28             4  0.65  0.05               1               1      0.995   \n",
       "29             4  0.65  0.05               1               1      0.995   \n",
       "...          ...   ...   ...             ...             ...        ...   \n",
       "16360          4  0.48  0.03               1               1      0.990   \n",
       "16361          4  0.48  0.03               1               1      0.984   \n",
       "16362          4  0.48  0.03               1               1      0.984   \n",
       "16363          4  0.48  0.03               1               1      0.984   \n",
       "16364          4  0.44  0.01               1               1      0.657   \n",
       "16365          4  0.44  0.01               1               1      0.657   \n",
       "16366          4  0.44  0.01               1               1      0.657   \n",
       "16367          4  0.44  0.01               1               1      0.648   \n",
       "16368          4  0.44  0.01               1               1      0.648   \n",
       "16369          4  0.44  0.01               1               1      0.648   \n",
       "16370          4  0.44  0.01               1               1      0.632   \n",
       "16371          4  0.44  0.01               1               1      0.632   \n",
       "16372          4  0.44  0.01               1               1      0.651   \n",
       "16373          4  0.44  0.01               1               1      0.651   \n",
       "16374          4  0.44  0.01               1               1      0.651   \n",
       "16375          4  0.44  0.01               1               1      0.694   \n",
       "16376          4  0.44  0.01               1               1      0.694   \n",
       "16377          4  0.44  0.01               1               1      0.694   \n",
       "16378          4  0.44  0.01               1               1      0.783   \n",
       "16379          4  0.44  0.01               1               1      0.783   \n",
       "16380          4  0.44  0.01               1               1      0.783   \n",
       "16381          4  0.44  0.01               1               1      0.845   \n",
       "16382          4  0.44  0.01               1               1      0.845   \n",
       "16383          4  0.44  0.01               1               1      0.845   \n",
       "16384          4  0.44  0.01               1               1      0.882   \n",
       "16385          4  0.44  0.01               1               1      0.882   \n",
       "16386          4  0.44  0.01               1               1      0.882   \n",
       "16387          4  0.44  0.01               1               1      0.904   \n",
       "16388          4  0.44  0.01               1               1      0.904   \n",
       "16389          4  0.44  0.01               1               1      0.904   \n",
       "\n",
       "       mamPhCons  verPhCons  priPhyloP  mamPhyloP    ...      DANN_rank_score  \\\n",
       "0          1.000      1.000      0.557      2.512    ...              0.97528   \n",
       "1          1.000      1.000      0.557      2.512    ...              0.96103   \n",
       "2          1.000      1.000      0.557      2.512    ...              0.97675   \n",
       "3          1.000      1.000      0.455      2.032    ...              0.97063   \n",
       "4          1.000      1.000      0.455      2.032    ...              0.93453   \n",
       "5          1.000      1.000      0.455      2.032    ...              0.93344   \n",
       "6          1.000      1.000      0.557      2.512    ...              0.97517   \n",
       "7          1.000      1.000      0.557      2.512    ...              0.95522   \n",
       "8          1.000      1.000      0.557      2.512    ...              0.97399   \n",
       "9          1.000      1.000      0.557      2.512    ...              0.97509   \n",
       "10         1.000      1.000      0.557      2.512    ...              0.96087   \n",
       "11         1.000      1.000      0.557      2.512    ...              0.97652   \n",
       "12         1.000      1.000      0.455      2.032    ...              0.93172   \n",
       "13         1.000      1.000      0.455      2.032    ...              0.93210   \n",
       "14         1.000      1.000      0.455      2.032    ...              0.96952   \n",
       "15         1.000      1.000      0.455      2.032    ...              0.97022   \n",
       "16         1.000      1.000      0.455      2.032    ...              0.93234   \n",
       "17         1.000      1.000      0.455      2.032    ...              0.93232   \n",
       "18         1.000      1.000      0.557      2.512    ...              0.97482   \n",
       "19         1.000      1.000      0.557      2.512    ...              0.95410   \n",
       "20         1.000      1.000      0.557      2.512    ...              0.97354   \n",
       "21         1.000      1.000      0.455      2.032    ...              0.93050   \n",
       "22         1.000      1.000      0.455      2.032    ...              0.93252   \n",
       "23         1.000      1.000      0.455      2.032    ...              0.96870   \n",
       "24         1.000      1.000      0.455      2.032    ...              0.93050   \n",
       "25         1.000      1.000      0.455      2.032    ...              0.93252   \n",
       "26         1.000      1.000      0.455      2.032    ...              0.96870   \n",
       "27         1.000      1.000      0.557      2.512    ...              0.97476   \n",
       "28         1.000      1.000      0.557      2.512    ...              0.96049   \n",
       "29         1.000      1.000      0.557      2.512    ...              0.97612   \n",
       "...          ...        ...        ...        ...    ...                  ...   \n",
       "16360      1.000      1.000      0.651      2.572    ...              0.94316   \n",
       "16361      1.000      1.000      0.651      2.572    ...              0.94762   \n",
       "16362      1.000      1.000      0.651      2.572    ...              0.87343   \n",
       "16363      1.000      1.000      0.651      2.572    ...              0.94433   \n",
       "16364      0.239      0.983      0.651      0.272    ...              0.76653   \n",
       "16365      0.239      0.983      0.651      0.272    ...              0.66923   \n",
       "16366      0.239      0.983      0.651      0.272    ...              0.70343   \n",
       "16367      0.251      0.982      0.530      0.923    ...              0.91490   \n",
       "16368      0.251      0.982      0.530      0.923    ...              0.85877   \n",
       "16369      0.251      0.982      0.530      0.923    ...              0.84657   \n",
       "16370      0.246      0.952     -1.260     -0.568    ...              0.40986   \n",
       "16371      0.246      0.952     -1.260     -0.568    ...              0.49639   \n",
       "16372      0.422      0.964     -0.180      0.241    ...              0.76591   \n",
       "16373      0.422      0.964     -0.180      0.241    ...              0.77179   \n",
       "16374      0.422      0.964     -0.180      0.241    ...              0.63616   \n",
       "16375      0.763      0.968     -0.144      0.696    ...              0.70816   \n",
       "16376      0.763      0.968     -0.144      0.696    ...              0.67881   \n",
       "16377      0.763      0.968     -0.144      0.696    ...              0.61037   \n",
       "16378      0.933      0.981      0.530      0.892    ...              0.68636   \n",
       "16379      0.933      0.981      0.530      0.892    ...              0.70324   \n",
       "16380      0.933      0.981      0.530      0.892    ...              0.81402   \n",
       "16381      0.988      0.996      0.651      1.122    ...              0.72138   \n",
       "16382      0.988      0.996      0.651      1.122    ...              0.67765   \n",
       "16383      0.988      0.996      0.651      1.122    ...              0.76342   \n",
       "16384      0.999      1.000      0.651      2.572    ...              0.90485   \n",
       "16385      0.999      1.000      0.651      2.572    ...              0.85433   \n",
       "16386      0.999      1.000      0.651      2.572    ...              0.86108   \n",
       "16387      1.000      1.000      0.530      2.079    ...              0.89756   \n",
       "16388      1.000      1.000      0.530      2.079    ...              0.92571   \n",
       "16389      1.000      1.000      0.530      2.079    ...              0.94816   \n",
       "\n",
       "       fathmm-MKL_non-coding_rankscore  Eigen-PC-phred  \\\n",
       "0                              0.98089         22.5234   \n",
       "1                              0.98105         22.5234   \n",
       "2                              0.98032         22.5234   \n",
       "3                              0.97882         22.5344   \n",
       "4                              0.97854         22.5344   \n",
       "5                              0.97900         22.5344   \n",
       "6                              0.98065         22.5658   \n",
       "7                              0.98124         22.5658   \n",
       "8                              0.98098         22.5658   \n",
       "9                              0.98089         22.5881   \n",
       "10                             0.98105         22.5881   \n",
       "11                             0.98032         22.5881   \n",
       "12                             0.97912         22.5917   \n",
       "13                             0.97887         22.5917   \n",
       "14                             0.97888         22.5917   \n",
       "15                             0.97882         22.6590   \n",
       "16                             0.97854         22.6590   \n",
       "17                             0.97900         22.6590   \n",
       "18                             0.98065         22.6896   \n",
       "19                             0.98124         22.6896   \n",
       "20                             0.98098         22.6896   \n",
       "21                             0.97912         22.6431   \n",
       "22                             0.97887         22.6431   \n",
       "23                             0.97888         22.6431   \n",
       "24                             0.97912         22.6369   \n",
       "25                             0.97887         22.6369   \n",
       "26                             0.97888         22.6369   \n",
       "27                             0.98089         22.6738   \n",
       "28                             0.98105         22.6738   \n",
       "29                             0.98032         22.6738   \n",
       "...                                ...             ...   \n",
       "16360                          0.99187         18.0687   \n",
       "16361                          0.99177         18.0736   \n",
       "16362                          0.99187         18.0736   \n",
       "16363                          0.99138         18.0736   \n",
       "16364                          0.97673         17.6863   \n",
       "16365                          0.97673         17.6863   \n",
       "16366                          0.97581         17.6863   \n",
       "16367                          0.98163         17.7454   \n",
       "16368                          0.98114         17.7454   \n",
       "16369                          0.98180         17.7454   \n",
       "16370                          0.97180         17.5270   \n",
       "16371                          0.97085         17.5270   \n",
       "16372                          0.97670         17.7196   \n",
       "16373                          0.97669         17.7196   \n",
       "16374                          0.97596         17.7196   \n",
       "16375                          0.97439         17.7793   \n",
       "16376                          0.97485         17.7793   \n",
       "16377                          0.97470         17.7793   \n",
       "16378                          0.97657         17.8690   \n",
       "16379                          0.97583         17.8690   \n",
       "16380                          0.97629         17.8690   \n",
       "16381                          0.98021         17.9016   \n",
       "16382                          0.98050         17.9016   \n",
       "16383                          0.97899         17.9016   \n",
       "16384                          0.99098         18.0379   \n",
       "16385                          0.99109         18.0379   \n",
       "16386                          0.99056         18.0379   \n",
       "16387                          0.98916         18.0369   \n",
       "16388                          0.98895         18.0369   \n",
       "16389                          0.98896         18.0369   \n",
       "\n",
       "       splicing_consensus_ada_score  splicing_consensus_rf_score  1000Gp3_AC  \\\n",
       "0                                 0                            0           0   \n",
       "1                                 0                            0           0   \n",
       "2                                 0                            0           0   \n",
       "3                                 0                            0           0   \n",
       "4                                 0                            0           0   \n",
       "5                                 0                            0           0   \n",
       "6                                 0                            0           0   \n",
       "7                                 0                            0           0   \n",
       "8                                 0                            0           0   \n",
       "9                                 0                            0           0   \n",
       "10                                0                            0           0   \n",
       "11                                0                            0           0   \n",
       "12                                0                            0           0   \n",
       "13                                0                            0           0   \n",
       "14                                0                            0           0   \n",
       "15                                0                            0           0   \n",
       "16                                0                            0           0   \n",
       "17                                0                            0           0   \n",
       "18                                0                            0           0   \n",
       "19                                0                            0           0   \n",
       "20                                0                            0           0   \n",
       "21                                0                            0           0   \n",
       "22                                0                            0           0   \n",
       "23                                0                            0           0   \n",
       "24                                0                            0           0   \n",
       "25                                0                            0           0   \n",
       "26                                0                            0           0   \n",
       "27                                0                            0           0   \n",
       "28                                0                            0           0   \n",
       "29                                0                            0           0   \n",
       "...                             ...                          ...         ...   \n",
       "16360                             0                            0           0   \n",
       "16361                             0                            0           0   \n",
       "16362                             0                            0           0   \n",
       "16363                             0                            0           0   \n",
       "16364                             0                            0           0   \n",
       "16365                             0                            0           0   \n",
       "16366                             0                            0           0   \n",
       "16367                             0                            0           0   \n",
       "16368                             0                            0           0   \n",
       "16369                             0                            0           0   \n",
       "16370                             0                            0           0   \n",
       "16371                             0                            0           0   \n",
       "16372                             0                            0           0   \n",
       "16373                             0                            0           0   \n",
       "16374                             0                            0           0   \n",
       "16375                             0                            0           0   \n",
       "16376                             0                            0           0   \n",
       "16377                             0                            0           0   \n",
       "16378                             0                            0           0   \n",
       "16379                             0                            0           0   \n",
       "16380                             0                            0           0   \n",
       "16381                             0                            0           0   \n",
       "16382                             0                            0           0   \n",
       "16383                             0                            0           0   \n",
       "16384                             0                            0           0   \n",
       "16385                             0                            0           0   \n",
       "16386                             0                            0           0   \n",
       "16387                             0                            0           0   \n",
       "16388                             0                            0           0   \n",
       "16389                             0                            0           0   \n",
       "\n",
       "       UK10K_AC  TWINSUK_AC  gnomAD_genomes_AC  TrimerAvg  \n",
       "0             0           0                  0  -0.211141  \n",
       "1             0           0                  0  -0.377813  \n",
       "2             0           0                  0  -0.141604  \n",
       "3             0           0                  0  -0.181379  \n",
       "4             0           0                  0  -0.107647  \n",
       "5             0           0                  0  -0.304091  \n",
       "6             0           0                  0  -0.194868  \n",
       "7             0           0                  0  -0.458889  \n",
       "8             0           0                  0  -0.123000  \n",
       "9             0           0                  0  -0.159767  \n",
       "10            0           0                  0  -0.377813  \n",
       "11            0           0                  0  -0.283621  \n",
       "12            0           0                  0  -0.249500  \n",
       "13            0           0                  0  -0.159423  \n",
       "14            0           0                  0  -0.065882  \n",
       "15            0           0                  0  -0.277857  \n",
       "16            0           0                  0  -0.107647  \n",
       "17            0           0                  0  -0.304091  \n",
       "18            0           0                  0  -0.194868  \n",
       "19            0           0                  0  -0.458889  \n",
       "20            0           0                  0  -0.276667  \n",
       "21            0           0                  0  -0.170652  \n",
       "22            0           0                  1  -0.159423  \n",
       "23            0           0                  0  -0.159423  \n",
       "24            0           0                  0  -0.159423  \n",
       "25            0           0                  0  -0.159423  \n",
       "26            0           0                  0  -0.167308  \n",
       "27            0           0                  0  -0.201250  \n",
       "28            0           0                  0  -0.377813  \n",
       "29            0           0                  0  -0.283621  \n",
       "...         ...         ...                ...        ...  \n",
       "16360         0           0                  0  -0.123000  \n",
       "16361         0           0                  0  -0.159767  \n",
       "16362         0           0                  0  -0.377813  \n",
       "16363         0           0                  0  -0.377813  \n",
       "16364         0           0                  0  -0.377813  \n",
       "16365         0           0                  0  -0.377813  \n",
       "16366         0           0                  0  -0.141604  \n",
       "16367         0           0                  0  -0.181379  \n",
       "16368         0           0                  0  -0.107647  \n",
       "16369         0           0                  0  -0.143000  \n",
       "16370         0           0                  0  -0.105769  \n",
       "16371         0           0                  0  -0.167308  \n",
       "16372         0           0                  0  -0.201250  \n",
       "16373         0           0                  0  -0.377813  \n",
       "16374         0           0                  0  -0.377813  \n",
       "16375         0           0                  0  -0.377813  \n",
       "16376         0           0                  0  -0.377813  \n",
       "16377         0           0                  0  -0.283621  \n",
       "16378         0           0                  0  -0.249500  \n",
       "16379         0           0                  0  -0.159423  \n",
       "16380         0           0                  0  -0.120962  \n",
       "16381         0           0                  0  -0.322500  \n",
       "16382         0           0                  0  -0.458889  \n",
       "16383         0           0                  0  -0.123000  \n",
       "16384         0           0                  0  -0.159767  \n",
       "16385         0           0                  0  -0.377813  \n",
       "16386         0           0                  0  -0.283621  \n",
       "16387         0           0                  0  -0.249500  \n",
       "16388         0           0                  0  -0.159423  \n",
       "16389         0           0                  0  -0.120962  \n",
       "\n",
       "[17061 rows x 93 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fancyimpute import BiScaler, KNN, NuclearNormMinimization, SoftImpute, MICE\n",
    "import random\n",
    "\n",
    "d=df[numeric_feats+['gene']]\n",
    "newd=pd.DataFrame()\n",
    "for i in df['gene'].unique().tolist():\n",
    "    print \"Doing gene \",i\n",
    "    dtemp=d[d['gene']==i][numeric_feats]\n",
    "    tempx=pd.DataFrame(data=KNN(k=3).complete(dtemp), columns=dtemp.columns, index=dtemp.index)\n",
    "    newd=pd.concat([newd,tempx])\n",
    "\n",
    "newd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=newd\n",
    "#X=pd.DataFrame(data=Ximp, columns=df[numeric_feats].columns, index=df[numeric_feats].index)\n",
    "X[cat_feats+['gene']]=df[cat_feats+['gene']]\n",
    "\n",
    "#X.to_csv('ImputedImcomplete.tsv',sep=\"\\t\",index=False)\n",
    "\n",
    "#X=df[numeric_feats+cat_feats]\n",
    "import category_encoders as ce\n",
    "encoder = ce.OneHotEncoder(cols=cat_feats+['gene'])\n",
    "X = encoder.fit_transform(X)\n",
    "\n",
    "#numeric_feats = df2.dtypes[df2.dtypes != \"object\"].index\n",
    "\n",
    "X2=X.shift(1)\n",
    "X2.columns = [str(col) + '_2' for col in X2.columns]\n",
    "X2=pd.concat([X,X2],axis=1).fillna(0)\n",
    "numeric_feats2= X2.dtypes[X2.dtypes != \"object\"].index\n",
    "\n",
    "labelX=['WhatSet','#chr','pos', 'ref','alt','gene']\n",
    "vals=['value','valuec','multic', 'confidence']\n",
    "X3=X2.join(df[labelX+vals])\n",
    "\n",
    "#X3.to_csv('ImputedMICE.tsv',sep=\"\\t\",index=False)\n",
    "\n",
    "trainset=X3[X3['WhatSet']==\"Train\"]\n",
    "X4train=trainset[numeric_feats2]\n",
    "testset=X3[X3['WhatSet']==\"Test\"]\n",
    "X4test=testset[numeric_feats2]\n",
    "y=trainset['value']\n",
    "yc=trainset['valuec']\n",
    "ym=trainset['multic']\n",
    "conf=trainset['confidence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerics2 = []\n",
    "features=X3[numeric_feats]\n",
    "for i in features.columns:\n",
    "    #print i\n",
    "    if features[i].dtype in numeric_dtypes: \n",
    "        numerics2.append(i)\n",
    "\n",
    "skew_features = features[numerics2].apply(lambda x: skew(x)).sort_values(ascending=False)\n",
    "skews = pd.DataFrame({'skew':skew_features})\n",
    "#skews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69 skewed numerical features to Box Cox transform\n"
     ]
    }
   ],
   "source": [
    "#skew_features[skew_features > 0.5]\n",
    "skewness = skew_features[abs(skew_features) > 0.75]\n",
    "print(\"There are {} skewed numerical features to Box Cox transform\".format(skewness.shape[0]))\n",
    "\n",
    "from scipy.special import boxcox1p\n",
    "skewed_features = skewness.index\n",
    "lam = 0.15\n",
    "for feat in skewed_features:\n",
    "    #all_data[feat] += 1\n",
    "    X3[feat] = boxcox1p(X3[feat], lam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset=X3[X3['WhatSet']==\"Train\"]\n",
    "X4train=trainset[numeric_feats2]\n",
    "testset=X3[X3['WhatSet']==\"Test\"]\n",
    "X4test=testset[numeric_feats2]\n",
    "y=trainset['value']\n",
    "yc=trainset['valuec']\n",
    "ym=trainset['multic']\n",
    "conf=trainset['confidence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# SETTINGS - CHANGE THESE TO GET SOMETHING MEANINGFUL\n",
    "ITERATIONS = 5 # 1000\n",
    "#TRAINING_SIZE = 100000 # 20000000\n",
    "#TEST_SIZE = 25000\n",
    "\n",
    "\n",
    "# Classifier\n",
    "bayes_cv_tuner = BayesSearchCV(\n",
    "    estimator = xgb.XGBClassifier(\n",
    "        n_jobs = 1,\n",
    "        objective = 'multi:softmax',\n",
    "        eval_metric = 'auc',\n",
    "        silent=1,\n",
    "        tree_method='approx'\n",
    "    ),\n",
    "    search_spaces = {\n",
    "        'learning_rate': (0.01, 1.0, 'log-uniform'),\n",
    "        'min_child_weight': (1, 20),\n",
    "        'max_depth': (1, 200),\n",
    "        'max_delta_step': (2, 20),\n",
    "        'subsample': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bytree': (0.01, 1.0, 'uniform'),\n",
    "        'colsample_bylevel': (0.01, 1.0, 'uniform'),\n",
    "        'reg_lambda': (1e-9, 1000, 'log-uniform'),\n",
    "        'reg_alpha': (1e-9, 1.0, 'log-uniform'),\n",
    "        'gamma': (1e-9, 0.5, 'log-uniform'),\n",
    "        'min_child_weight': (0, 5),\n",
    "        'n_estimators': (50, 1000),\n",
    "        'scale_pos_weight': (1e-6, 500, 'log-uniform')\n",
    "    },    \n",
    "    #scoring = 'merror',\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=5,\n",
    "        shuffle=True,\n",
    "        random_state=42\n",
    "   ),\n",
    "    n_jobs = 3,\n",
    "    n_iter = ITERATIONS,   \n",
    "    verbose = 0,\n",
    "    refit = True,\n",
    "    random_state = 21\n",
    ")\n",
    "\n",
    "def status_print(optim_result):\n",
    "    \"\"\"Status callback durring bayesian hyperparameter search\"\"\"\n",
    "    \n",
    "    # Get all the models tested so far in DataFrame format\n",
    "    all_models = pd.DataFrame(bayes_cv_tuner.cv_results_)    \n",
    "    \n",
    "    # Get current parameters and the best parameters    \n",
    "    best_params = pd.Series(bayes_cv_tuner.best_params_)\n",
    "    print('Model #{}\\nBest ROC-AUC: {}\\nBest params: {}\\n'.format(\n",
    "        len(all_models),\n",
    "        np.round(bayes_cv_tuner.best_score_, 4),\n",
    "        bayes_cv_tuner.best_params_\n",
    "    ))\n",
    "    \n",
    "    # Save all model results\n",
    "    #clf_name = bayes_cv_tuner.estimator.__class__.__name__\n",
    "    #all_models.to_csv(clf_name+\"_cv_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #1\n",
      "Best ROC-AUC: 0.5885\n",
      "Best params: {'reg_alpha': 0.0026816514096993705, 'colsample_bytree': 0.04274813813171353, 'colsample_bylevel': 0.4443970361486894, 'scale_pos_weight': 0.003335627056352342, 'learning_rate': 0.28172017106108804, 'max_delta_step': 3, 'min_child_weight': 4, 'n_estimators': 978, 'subsample': 0.6098650890849483, 'reg_lambda': 9.475008014117794e-08, 'max_depth': 169, 'gamma': 8.629527922731328e-07}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #2\n",
      "Best ROC-AUC: 0.6079\n",
      "Best params: {'reg_alpha': 3.9941272090415406e-07, 'colsample_bytree': 0.2855220483293149, 'colsample_bylevel': 0.026484639294976874, 'scale_pos_weight': 2.9661395674520715e-05, 'learning_rate': 0.045916158374398955, 'max_delta_step': 19, 'min_child_weight': 1, 'n_estimators': 596, 'subsample': 0.29236338804092304, 'reg_lambda': 2.488928256040396e-09, 'max_depth': 63, 'gamma': 0.0013357199220082401}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #3\n",
      "Best ROC-AUC: 0.6079\n",
      "Best params: {'reg_alpha': 3.9941272090415406e-07, 'colsample_bytree': 0.2855220483293149, 'colsample_bylevel': 0.026484639294976874, 'scale_pos_weight': 2.9661395674520715e-05, 'learning_rate': 0.045916158374398955, 'max_delta_step': 19, 'min_child_weight': 1, 'n_estimators': 596, 'subsample': 0.29236338804092304, 'reg_lambda': 2.488928256040396e-09, 'max_depth': 63, 'gamma': 0.0013357199220082401}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #4\n",
      "Best ROC-AUC: 0.6079\n",
      "Best params: {'reg_alpha': 3.9941272090415406e-07, 'colsample_bytree': 0.2855220483293149, 'colsample_bylevel': 0.026484639294976874, 'scale_pos_weight': 2.9661395674520715e-05, 'learning_rate': 0.045916158374398955, 'max_delta_step': 19, 'min_child_weight': 1, 'n_estimators': 596, 'subsample': 0.29236338804092304, 'reg_lambda': 2.488928256040396e-09, 'max_depth': 63, 'gamma': 0.0013357199220082401}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/h/aashish/.local/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model #5\n",
      "Best ROC-AUC: 0.6079\n",
      "Best params: {'reg_alpha': 3.9941272090415406e-07, 'colsample_bytree': 0.2855220483293149, 'colsample_bylevel': 0.026484639294976874, 'scale_pos_weight': 2.9661395674520715e-05, 'learning_rate': 0.045916158374398955, 'max_delta_step': 19, 'min_child_weight': 1, 'n_estimators': 596, 'subsample': 0.29236338804092304, 'reg_lambda': 2.488928256040396e-09, 'max_depth': 63, 'gamma': 0.0013357199220082401}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = bayes_cv_tuner.fit(X4train.values, ym, callback=status_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestp= bayes_cv_tuner.best_params_\n",
    "\n",
    "clf2=xgb.XGBClassifier()\n",
    "clf2.set_params(**bestp)\n",
    "\n",
    "clf2.fit(X4train,ym)\n",
    "pd.Series(clf2.feature_importances_,index=list(X4train.columns.values)).sort_values(ascending=True).head(50).plot(kind='barh',figsize=(12,18),title='XGBOOST FEATURE IMPORTANCE')\n",
    "\n",
    "#feati=gene+'_feat.png'\n",
    "#plt.savefig(feati)\n",
    "plt.show()\n",
    "\n",
    "mcpred=clf2.predict(X4train)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(mcpred,ym),annot=True,fmt='2.0f')\n",
    "#confu=gene+'_conf.png'\n",
    "#plt.savefig(confu)\n",
    "plt.show()\n",
    "\n",
    "clf2.fit(X4train,ym)\n",
    "pred=clf2.predict(X4test)\n",
    "proba=clf2.predict_proba(X4test)\n",
    "\n",
    "testset['Direction']=pred\n",
    "testset['P_Direction']=proba[:,0]\n",
    "\n",
    "clf2.fit(X4train,conf)\n",
    "predc=clf2.predict(X4test)\n",
    "probac=clf2.predict_proba(X4test)\n",
    "\n",
    "testset['Confidence']=predc\n",
    "testset['SE']=probac[:,0]\n",
    "\n",
    "out=testset[['#chr', 'pos', 'ref','alt','gene', 'Direction','P_Direction', 'Confidence', 'SE']]\n",
    "out.to_csv('Predictions/XGBOOST_Allfeatureswithneighbor_XGBOOSTonly_multiclass.tsv',sep=\"\\t\")                                                                                                  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
